# -*- coding: utf-8 -*-
"""
Created on Mon Oct 27 17:38:16 2025

@author: USER
"""

# ============================================
# ç¬¬ 0 æ­¥ï¼šè¼‰å…¥å¿…è¦çš„å¥—ä»¶
# ============================================

# pandasï¼šè™•ç†è¡¨æ ¼è³‡æ–™
# scikit-learnï¼šæä¾›MLæ¨¡å‹èˆ‡è³‡æ–™å‰è™•ç†å·¥å…·
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# ============================================
# ç¬¬ 1 æ­¥ï¼šå»ºç«‹è¨“ç·´è³‡æ–™ (æ¨¡æ“¬ NanoDCAL è¼¸å‡º)
# ============================================

# æˆ‘å€‘å…ˆç”¨ä¸€å°ç­†æ¨¡æ“¬è³‡æ–™å–ä»£çœŸå¯¦æ¨¡æ“¬çµæœã€‚
# é€™äº›æ•¸å€¼ä»£è¡¨ä¸åŒçµæ§‹ä¸‹çš„é›»å­ç©¿éš§è¡Œç‚ºã€‚

np.random.seed(42)  # å›ºå®šäº‚æ•¸è®“çµæœå¯é‡ç¾

# -----------------------------
# 1ï¸âƒ£ ç”¢ç”Ÿçµæ§‹åƒæ•¸ (features)
# -----------------------------
n_samples = 100

barrier_thickness_nm = np.random.uniform(0.8, 1.6, n_samples)  # åšåº¦ 0.8~1.6 nm
Ef_T = np.random.uniform(0.3, 0.95, n_samples)                  # å‚³è¼¸ä¿‚æ•¸ 0.3~0.95
materials = np.random.choice(["MgO", "Al2O3"], n_samples)        # å…©ç¨®ææ–™
interfaces = np.random.choice(["Fe-O-Mg", "Fe-Mg-O", "Fe-O-Al", "Fe-Al-O"], n_samples)

# -----------------------------
# 2ï¸âƒ£ æ ¹æ“šç‰©ç†é‚è¼¯æ¨¡æ“¬é›»æµ (target)
# -----------------------------
# åŸºæœ¬æ¨¡å‹ï¼šI ~ T(E) * exp(-Î± * thickness)
alpha = 2.5  # ä»£è¡¨ç©¿éš§é˜»ç¤™å¼·åº¦
base_current = 20 * Ef_T * np.exp(-alpha * (barrier_thickness_nm - 0.8))

# æ ¹æ“šææ–™èª¿æ•´æ¯”ä¾‹
for i in range(n_samples):
    if materials[i] == "MgO":
        base_current[i] *= 1.0  # MgO ç‚ºåŸºæº–
    else:
        base_current[i] *= 0.8  # Al2O3 å°é›»æ€§ç¨å¼±

# åŠ å…¥å°‘è¨±éš¨æ©Ÿé›œè¨Šï¼ˆæ¨¡æ“¬è¨ˆç®—æˆ–é‡æ¸¬èª¤å·®ï¼‰
noise = np.random.normal(0, 0.8, n_samples)
I_at_0_1V = np.clip(base_current + noise, 0, None)  # Î¼A, ä¸å…è¨±è² é›»æµ

# -----------------------------
# 3ï¸âƒ£ çµ„æˆ DataFrame
# -----------------------------
df = pd.DataFrame({
    "barrier_thickness_nm": barrier_thickness_nm,
    "barrier_material": materials,
    "interface_atom_order": interfaces,
    "Ef_T(E)": Ef_T,
    "I_at_0.1V_uA": I_at_0_1V
})

print(df.head(10))
print(f"\nâœ… è³‡æ–™ç­†æ•¸: {len(df)}")

# ============================================
# ğŸ§® ç¬¬ 2 æ­¥ï¼šå®šç¾©ç‰¹å¾µèˆ‡ç›®æ¨™
# ============================================

# æˆ‘å€‘æƒ³é æ¸¬åœ¨ 0.1 V ä¸‹çš„é›»æµ (I_at_0.1V_uA)
# ç‰¹å¾µï¼ˆinputsï¼‰åŒ…å«åšåº¦ã€ææ–™ã€ç•Œé¢æ’åˆ—ã€T(E)
X = df[["barrier_thickness_nm", "barrier_material", "interface_atom_order", "Ef_T(E)"]]
y = df["I_at_0.1V_uA"]

# ============================================
# ç¬¬ 3 æ­¥ï¼šå°æ–‡å­—ç‰¹å¾µåš One-Hot ç·¨ç¢¼
# ============================================

# é€™æ˜¯æŠŠæ–‡å­—è½‰æˆæ©Ÿå™¨å¯ç†è§£çš„æ•¸å€¼ç‰¹å¾µã€‚
# ä¾‹å¦‚ï¼šMgO â†’ [1,0]ï¼›Al2O3 â†’ [0,1]
categorical_features = ["barrier_material", "interface_atom_order"]
preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(), categorical_features)
    ],
    remainder="passthrough"  # å…¶ä»–æ•¸å€¼æ¬„ä½ä¿æŒåŸæ¨£
)

# ============================================
# ç¬¬ 4 æ­¥ï¼šå»ºç«‹éš¨æ©Ÿæ£®æ—è¿´æ­¸æ¨¡å‹
# ============================================

# RandomForest æ˜¯ä¸€ç¨®ç©©å®šä¸”è§£é‡‹æ€§å¼·çš„éç·šæ€§æ¨¡å‹
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(
        n_estimators=200,  # æ¨¹çš„æ•¸é‡
        random_state=42,
        max_depth=None     # è®“æ¨¡å‹è‡ªå‹•æ±ºå®šæ·±åº¦
    ))
])

# ============================================
# ç¬¬ 5 æ­¥ï¼šåˆ‡åˆ†è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™
# ============================================

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ============================================
# ç¬¬ 6 æ­¥ï¼šè¨“ç·´æ¨¡å‹
# ============================================

model.fit(X_train, y_train)

# ============================================
# ç¬¬ 7 æ­¥ï¼šæ¨¡å‹è©•ä¼°
# ============================================

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nğŸ“Š æ¨¡å‹è©•ä¼°çµæœï¼š")
print(f"å¹³å‡çµ•å°èª¤å·® (MAE): {mae:.3f}")
print(f"æ±ºå®šä¿‚æ•¸ RÂ²: {r2:.3f}")

# ç•«å‡ºé æ¸¬ vs å¯¦éš› çš„æ•£ä½ˆåœ–
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, color='royalblue', s=70)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
plt.xlabel("real current (Î¼A)")
plt.ylabel("predic current (Î¼A)")
plt.title("predic vs real")
plt.text(min(y_test)+0.1, max(y_test)-0.5, "Slope = 1.0", color='red')
plt.grid(True)
plt.show()

# ============================================
# ç¬¬ 8 æ­¥ï¼šç”¨æ¨¡å‹é æ¸¬æ–°çµæ§‹
# ============================================

# å‡è¨­æœ‰å…©å€‹æ–°çµæ§‹ï¼Œæƒ³çœ‹ AI è¦ºå¾—å°é›»è¡¨ç¾å¦‚ä½•
new_samples = pd.DataFrame({
    "barrier_thickness_nm": [1.3, 0.9],
    "barrier_material": ["MgO", "Al2O3"],
    "interface_atom_order": ["Fe-O-Mg", "Fe-O-Al"],
    "Ef_T(E)": [0.45, 0.60]
})

predicted_currents = model.predict(new_samples)
print("\nğŸ”® æ–°çµæ§‹é æ¸¬çµæœï¼š")
for i, val in enumerate(predicted_currents):
    print(f"çµæ§‹ {i+1} çš„é æ¸¬é›»æµ â‰ˆ {val:.2f} Î¼A")

# ============================================
# ç¬¬ 9 æ­¥ï¼ˆé€²éšï¼‰ï¼šæŸ¥çœ‹ç‰¹å¾µé‡è¦æ€§
# ============================================

# Random Forest å¯ä»¥å‘Šè¨´æˆ‘å€‘å“ªå€‹ç‰¹å¾µå°æ¨¡å‹å½±éŸ¿æœ€å¤§
feature_names = model.named_steps["preprocessor"].get_feature_names_out()
importances = model.named_steps["regressor"].feature_importances_

plt.figure(figsize=(8,4))
plt.barh(feature_names, importances, color='teal')
plt.xlabel("Feature Importance")
plt.title("The contribution of different features to conductivity prediction")
plt.show()
